{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df06abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7b8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Add bias term to features\n",
    "X_train_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_test_bias = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "\n",
    "# One-hot encoding of target labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_onehot = np.eye(num_classes)[y_train]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Cross-entropy loss function\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.sum(y_true * np.log(y_pred)) / len(y_true)\n",
    "\n",
    "# Gradient descent optimization\n",
    "def gradient_descent(X, y, alpha, epochs):\n",
    "    weights = np.zeros((X.shape[1], num_classes))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        logits = np.dot(X, weights)\n",
    "        y_pred = softmax(logits)\n",
    "\n",
    "        loss = cross_entropy_loss(y, y_pred)\n",
    "        gradient = np.dot(X.T, (y_pred - y)) / len(y)\n",
    "\n",
    "        weights -= alpha * gradient\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a5ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the softmax regression model\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "weights = gradient_descent(X_train_bias, y_train_onehot, learning_rate, num_epochs)\n",
    "\n",
    "# Predictions on the test set\n",
    "logits_test = np.dot(X_test_bias, weights)\n",
    "y_pred_test = softmax(logits_test)\n",
    "predicted_classes = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "# Accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(f\"Accuracy on Test Set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1903ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "logits_test = np.dot(X_test_bias, weights)\n",
    "y_pred_test = softmax(logits_test)\n",
    "predicted_classes = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "# Accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "print(f\"Accuracy on Test Set: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
